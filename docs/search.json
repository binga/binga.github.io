[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Phani Srikanth",
    "section": "",
    "text": "testing."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to my home!",
    "section": "",
    "text": "üî≠ I‚Äôm currently working on helping my teammates succeed in protecting users from malicious file-based and web-based attacks using Machine Learning at Microsoft.\nüå± I‚Äôm learning how to lead great teams!\nüí¨ Ask me about Data Science / Building Career Paths / Storytelling / Interesting People on Internet / Systems Thinking.\nüì´ How to reach me: Twitter / LinkedIn / Microsoft\nüòÑ Pronouns: He/Him.\n‚ö° Fun fact: I never uttered a word until I turned 3.\n\nRead more about me here."
  },
  {
    "objectID": "recommendations.html",
    "href": "recommendations.html",
    "title": "Recommendations",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n¬†\n\n\n\n\n4 min\n\n\n\ndata science\n\n\ncompetitions\n\n\nmachine learning\n\n\nhackathons\n\n\n\n\n\n\n\nMar 30, 2017\n\n\n\n\n\n\n\n\n\n\n¬†\n\n\n\n\n2 min\n\n\n\ndata science\n\n\ncompetitions\n\n\nmachine learning\n\n\nhackathons\n\n\nHackerEarth\n\n\n\n\n\n\n\nDec 16, 2016\n\n\n\n\n\n\n\n\n\n\n¬†\n\n\n\n\n4 min\n\n\n\ndata science\n\n\ncompetitions\n\n\nmachine learning\n\n\nhackathons\n\n\nAnalytics Vidhya\n\n\n\n\n\n\n\nSep 15, 2015\n\n\n\n\n\n\n\n\n\n\n¬†\n\n\n\n\n2 min\n\n\n\ndata science\n\n\ncompetitions\n\n\nmachine learning\n\n\nhackathons\n\n\n\n\n\n\n\nAug 15, 2015\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2016-12-16-Winning_HackerEarth_ML_Challenge/index.html",
    "href": "posts/2016-12-16-Winning_HackerEarth_ML_Challenge/index.html",
    "title": "Winning the HackerEarth Machine Learning challenge",
    "section": "",
    "text": "Societe Generale, one of the largest banks in France, in collaboration with HackerEarth, organised Brainwaves, the annual hackathon at Bengaluru on November 12‚Äì13, 2016. The theme of the hackathon this year was ‚ÄúMachine Learning‚Äù. The hackathon had an online qualifier from where 85 top teams out of 2200 registrations from all over India, were selected for the final round. The final round was a 30-hour long hackathon which needed the teams to solve 1 problem out of 3 given problems spanning across transaction fraud detection, image and text analytics. I decided to solve the former since I have had experience working with banking data in multiple firms I have previously worked with."
  },
  {
    "objectID": "posts/2016-12-16-Winning_HackerEarth_ML_Challenge/index.html#brief-approach",
    "href": "posts/2016-12-16-Winning_HackerEarth_ML_Challenge/index.html#brief-approach",
    "title": "Winning the HackerEarth Machine Learning challenge",
    "section": "Brief Approach",
    "text": "Brief Approach\nFor the first problem, we were given millions of historical transactions to find patterns from and use these patterns to find anomalies on future transactions. We quickly skimmed through the data and built our machine learning model to predict the fraud on future transactional data and ranked #1 on the leaderboard. Eventually, we also built dashboards which can be used for proactive real-time monitoring for detection of any kind of new anomalies, or they can also be used to monitor transaction throughput etc. You could think of it like a one stop control centre with a global view of what‚Äôs going through the system. One commonly known fraudulent behaviour is, fraudsters try to exploit the system by doing high number of small debits and one large credit, thus swindling the money across countries and exchanges and hence trying to circumvent the defences of the system. This particular kind was quite challenging to incorporate into our machine learning model on and we are glad to have solved it to a good extent in 30 hours. Eventually, we had a good dashboard, a very good model and made an excellent pitch to the jury and ranked 1st amongst 85 teams."
  },
  {
    "objectID": "posts/2016-12-16-Winning_HackerEarth_ML_Challenge/index.html#experiences-at-the-hackathon",
    "href": "posts/2016-12-16-Winning_HackerEarth_ML_Challenge/index.html#experiences-at-the-hackathon",
    "title": "Winning the HackerEarth Machine Learning challenge",
    "section": "Experiences at the hackathon",
    "text": "Experiences at the hackathon\nThe hackathon was very well organised in terms of the quality of problem statements in the online and offline rounds, the way the organising team responded to any queries. It was genuinely surprising to see many mentors walking down to our table, talking to us about our backgrounds and providing us various domain related insights which augmented our model and resulted in higher performance. Even during the late hours none of them really left the place, they would always come and check if we were stalled anywhere and help us directionally so that we make constant progress. Having participated in a lot of hackathons prior to this one, I am very surprised by the energy levels of the mentors at Societe Generale.\nTo conclude, I would like to thank HackerEarth, Societe Generale, mentors and most importantly Phani Srinath and Supreeth Manyam for their fantastic work during the weekend. Great work guys! If not for any of the above, I am sure that weekend wouldn‚Äôt have been so memorable.\nAnd yes‚Ä¶ we partied long and hard that night! :-)\n  \nOur team with the amazing mentors and Societe Generale India CEO\nTop 3 teams pose for the customary picture. Overall, November 2016 has been a great month since Supreeth Manyam and I have also ended up winning another machine learning contest on CrowdAnalytix. We participated with the moniker Popeye For Olive!\nThat‚Äôs it for now. Stay tuned‚Ä¶"
  },
  {
    "objectID": "posts/2017-03-30-Winning_Two_ML_Challenges/index.html",
    "href": "posts/2017-03-30-Winning_Two_ML_Challenges/index.html",
    "title": "Winning two Machine Learning Challenges in the same month",
    "section": "",
    "text": "Analytics Roadshow MiniHack The first of these challenges was a mini-hack in which participants had three hours of time to build the most accurate predictive model that predicts surge pricing type for a taxi aggregator so that the matchmaking between the right cabs and right customers is quick and efficient.\nAfter a quick exploration of data, I encoded the Gender, Type of Cab and Confidence Life Style Index to numerical values so that tree models could consume the data. A 3-hour challenge doesn‚Äôt give you too much room to start with feature engineering. Hence, I directly jumped to building models to quickly test what works and what doesn‚Äôt. Linear models and Random forests produced around 0.63 and 0.68 on both cross-validation and leaderboard respectively. However, these stood around top 30th percentile. XGBoost, once again outperformed other models and it put me one among top 5 on leaderboard within an hour of the challenge. However, it was difficult to make any improvements to this.\n\nWhat didn‚Äôt work\n2-way variable interactions especially between var1, var2, var3 didn‚Äôt improve the score. Feature selection didn‚Äôt add any value. Ensembling RFs with XGBs produced no good effect. In a lot of ways, I was stuck for a long time. 30 minutes to finish line. I dropped to 15th position among 170 participants.\n\n\nWhat worked\nAs ensembling wasn‚Äôt working, I focused on improving my XGB model. I changed the min_child_weight parameter and voila! my score shot up. I was totally underfitting all the time, damn. I went up by 8 places. 15 minutes to go, I quickly lowered my learning_rate, my cross-validation score went up and it scored 2nd on LB! Falling short of time, I couldn‚Äôt add any other model. I was sure I didn‚Äôt overfit and I was delighted to see that my model was one of the most stable models on public and private and I scored 1st on private leaderboard.\nMaybe, it ain‚Äôt over until it‚Äôs over.\nRef: https://datahack.analyticsvidhya.com/contest/minihack-machine-learning/lb\nSource code here: https://github.com/binga/AnalyticsVidhya_Minihack\n2 weekends later..\n\n\nMLWare 2‚Äî Recommendation Challenge\nThis challenge was about building a model that predicts a given user‚Äôs ratings (from 0 to 10 stars) for a given item based on past ratings on other items and/or other information. The dataset approximately had one million data points and contained information about 40000 users, 120 items and the distribution of ratings was good enough to build a good recommendation engine.\n\nAs we were only given user_id, item_id and rating, there was no scope for feature engineering in this challenge. The data contained about a million data points and hence I split the entire dataset into a train and a validation set without any cross-validation loops. I started off with a collaborative filtering model in Python and a single CF model with 50 factors scored in the top 20%ile on leaderboard. Increasing or decreasing number of latent factors wasn‚Äôt contributing to an increase in score. However, ensembling 5 same kind of CF models with different random seed gave a significant boost, almost up to 3% and this model put me 2nd on the leaderboard, at the end of day one (in a 3-day challenge).\nUp next, I built a few LightGBM models to ensemble with the CF model. I used user-user features, user-item features like number of items rated by each user, {mean, median, max, min} rating by each user and all these features helped the LightGBM generalize well.\n\nWhat didn‚Äôt work\n\nXGBoost with the same features gave worser scores than LightGBM.\nAddition of item-item features didn‚Äôt contribute to the overall score.\nNeural network based collaborative filtering didn‚Äôt help improve the score.\n\n\n\nWhat worked\n\nSimple CF models and blended average.\nGBM models with user-item features.\n\nWith a weighted ensemble of CF model and LightGBM model, my model was good enough for a 2nd position on the leaderboard. On day 3 of the challenge, Rohan Rao who was 3rd on the leaderboard and I decided to team up. Rohan had multiple SVD models and a XGBoost stacker as his best model. This model‚Äôs score was close enough to my score but when we teamed up, our submissions correlation was 0.91 which was the most interesting thing. Immediately, we knew an average of both of our best models was going to do well and when we submitted this model, we zoomed to #1 position on the leaderboard. We tried a few things during the last hours of the competition but couldn‚Äôt improve the score.\nIn the end, we were glad to have maintained enough lead to remain #1 on the private leaderboard. Reference: https://datahack.analyticsvidhya.com/contest/mlware-2/lb\nThis marked the end of a good month where I ended up winning both the challenges I have taken part in. This is my 4th consecutive win in a hackathon. As I have lost one yesterday on HackerEarth, my good streak has finally come to an end and I decided to write down about the previous ones.\nWell, that‚Äôs it for today and I‚Äôm looking forward to do some more interesting and exciting work in the coming months.\nCheers!"
  },
  {
    "objectID": "posts/2015-08-18-DataScience_Hackathon_Datameet/index.html",
    "href": "posts/2015-08-18-DataScience_Hackathon_Datameet/index.html",
    "title": "Data Science Hackathon ‚Äî DataMeet Mumbai",
    "section": "",
    "text": "Problem Statement: Propensity model development ‚Äìthe client has a couple of use cases where they have not been able to get 80% response capture in top 3 deciles / >3X lift in the top decile ‚Äî inspite of several iterations. The expectation here would be identification of any new technique / algorithm (apart from logistic regression), which can help get the desired model performance.\nVarious kinds of customer data was given to us for utilizing in the data analysis. We were asked to figure out which customers are potential loan takers. The data given to us had a train set and a test set, total amounting to 8 lakh records and various features of each of the customers. The evaluation metric seemed trickier at first. I have often worked with logloss and AUC for binary classification problems. But, this problem was aspiring for higher lift in the top 10% and 30% recommendations.\nWe initially started with linear models and observed that the lift we were able to achieve was worser than the benchmark. Therefore, we switched to nonlinear models like decision trees and ensembles like Random Forest. Forests were able to produce much better results. But, due to the inherent nature of forests, the probabilities aren‚Äôt uniformly calibrated. So, we had to choose an algorithm that directly optimized the evaluation metric and thus we chose XGBoost (which is by far the most popular tool on Kaggle) which is fast and optimized the right evaluation metric and we observed that the XGBoost was performing way better than forests. As the requirement from the organizers included fast computation and cross-platform support, we stuck with XGBoost instead of creating complex ensembles which are engineering-heavy, and choose to take the feature creation route.\n\nOne of our teammates focused on creation of various features while the others focused on modeling and pushing the accuracy. We were pretty happy to obtain a lift of 5.5x while the benchmark was around 3x. Thus we chose to stick with 1 model!\nOn Sunday, we met the organizers and they were pretty happy with the model performance and they gave us 5 more days to increase the accuracy. But, we could only push it by 1% considering the heavy engineering effort required to make a significant progress.\nAfter 2 weeks of evaluation, I received a mail today from them saying, we stood 2nd on the competition from the total pool of 15 teams which are from various parts of India and from reputed universities like CMU etc.\nI‚Äôm pretty happy with the 2nd position finish as this is the first time I ended up winning a Data Science Challenge.\nI hope there are many more to come!"
  },
  {
    "objectID": "posts/2015-09-15-AnalyticsVidhya_3.X_Hackathon/index.html",
    "href": "posts/2015-09-15-AnalyticsVidhya_3.X_Hackathon/index.html",
    "title": "Analytics Vidhya 3.X Hackathon",
    "section": "",
    "text": "Problem Statement: Digital arms of banks today face challenges with lead conversion, they source leads through mediums like search, display, email campaigns and via affiliate partners. Here Happy Customer Bank faces same challenge of low conversion ratio. They have given a problem to identify the customers segments having higher conversion ratio for a specific loan product so that they can specifically target these customers.\nIt was eerily similar to a problem statement I‚Äôve worked with, 2 weeks earlier to this competition. I quickly jumped onto the dataset and noticed that the dataset was quite small and it was easy to run several experiments over the stipulated 2 days of time.\nThe evaluation metric of this competition was AUC score. So, I once went through the ‚Äúrank averaging‚Äù section on this awesome ensembling guide. This article should be read multiple times by any data analyst participating in a data science competition. Also, check out my 5 minutes to understand AUC guide I posted on Kaggle forums.\nAs a first step, I established the pipeline ‚Äî reading data, extracting a few basic features, building a simple classifier, generating the predictions file in a couple of hours and then went through the feature extraction as the time progressed. As it was a 2-day hackathon, we had to use the best tools available and snatch the lead. Once again, linear models failed to get me a good score and models like Random Forest worked well. As expected, XGBoost again did phenomenally well on the dataset.\nThe crucial points I noted while I worked on this dataset were: 1. When a high-cardinality categorical variable like ‚Äúcity‚Äù or ‚Äústate‚Äù is given, try to use it. Also, merge all rare levels. Really helps! 2. XGBoost has a way to treat missing values. Sometimes it‚Äôs better to leave the missing values as-is and allow the algorithm to take a decision on how to deal with them. 3. For Random Forests, I treated the missing values as -3.14, just as some other level. 4. Use dates whenever given. You could extract day, day of week, month, quarter, year and do forward subset selection for a start!\nIn the beginning, I was leading on the leaderboard but soon, others like phani_srinath have taken an insane lead on the LB. I was lucky to figure out my mistake in tuning the XGB and I could improve my score. Somehow, I was unable to get my Random Forest to work well and I was out of tricks. Then came in the defining moment. I tried FTRL, an online linear model (an algorithm Google uses in its ad-prediction engine) and it worked! This came in as a shocking/pleasant surprise and I did weighted ensembling. Inspite of all this, I ended up 2nd on the private leaderboard, losing by a tiny 0.00032., though, I was happy that I lost to an incredibly tough competitor.\n\nPhani Srinath finished 1st and I marginally missed out on the weekend contest! Fortunately, a few participants asked the organizers to extend the competition for a few more days and they obliged and extended it for 5 more days. This time I wanted to make sure I give my best shot. To demonstrate how close was the competition, the organizers revealed just the top 2 private scores before the 2nd leg of the competition and this gave me and phani_srinath an unfair lead. So, we gave out our approach to all the participants on the forum. And everybody picked it up so well that I ended up 10th on the public leaderboard in the weeklong competition. This time I built 10XGB models, 5 RF models, 5 FTRL models, averaged them for stability and made sure I ensemble my models well and made a gamble. Fortunately, it worked and Yayy! I finished highest on the private leaderboard of the weeklong competition and secured 1st position out of ~60 odd participants! I was only 50% sure about this because my CV scores were pretty strong and I used ensembling, way too much, to effectively fight variance in the dataset.\nThis time I finished 1st and Phani Srinath finished 3rd on the weeklong contest.\n\nI also gave out a small guide, how to effectively cross-validate with XGBoost. See here!\nI am happy that I secured 2 podium finishes and 1 win in this hackathon. This makes it 2 prizes in a month. The previous one was this. Very lucky 30 days it has been!\nFor other details, check out my codes on github!\nHopefully, I continue to learn more and more, and do well on future competitions. Game on!\nFinally, a shout-out to the AWESOME ‚ÄòT‚Äô trio,\n\nTianqi ‚Äî creator of XGBoost\nTriskelion ‚Äî for his brilliant ensembling guide\nTinrtgu ‚Äî he deserves an oscar for his beautiful online-lr FTRL code!"
  }
]